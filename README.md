# üöÄ 2Long2Read - Analyseur de CGU avec Claude AI

**Syst√®me d'analyse automatique de Terms & Conditions utilisant Claude AI, MongoDB, Prometheus et Grafana sur Kubernetes.**

---

## üìã Pr√©requis

Avant de commencer, assure-toi d'avoir :

- **Docker Desktop** install√© et en cours d'ex√©cution
- **kubectl** install√© (inclus avec Docker Desktop)
- **Helm** install√© (gestionnaire de packages Kubernetes)
- **Python 3.11+** avec pip
- **Une cl√© API Anthropic** (Claude AI)

### V√©rification rapide

```bash
docker --version
kubectl version --client
helm version
python3 --version
```

---

## üõ†Ô∏è Installation Compl√®te (√âtape par √âtape)

### 1. Cloner le projet

```bash
git clone <url-du-repo>
cd theprojectthathelpsyoubetterunderstndhowyourdataisusedineverycompanystermsandconditionsbecausenooneverreadsthem
```

### 2. Configurer l'environnement Python

```bash
# Cr√©er un environnement virtuel
python3 -m venv .venv

# Activer l'environnement
source .venv/bin/activate  # macOS/Linux
# ou
.venv\Scripts\activate     # Windows

# Installer les d√©pendances
pip install -r requirements.txt
```

### 3. Configurer la cl√© API Claude

```bash
# Cr√©er le secret Kubernetes pour Claude AI
kubectl create secret generic claude-api-key-secret \
  --from-literal=ANTHROPIC_API_KEY="ta-cl√©-api-ici"

# V√©rifier que le secret est cr√©√©
kubectl get secrets
```

### 4. Construire les images Docker

```bash
# Image de l'API
docker build -t 2long2read-api:latest -f Dockerfile .

# Image du Worker
docker build -t 2long2read-worker:latest -f Dockerfile.worker .

# V√©rifier les images
docker images | grep 2long2read
```

### 5. D√©ployer l'infrastructure sur Kubernetes

```bash
# D√©ployer MongoDB
kubectl apply -f k8s-infra.yaml

# Attendre que MongoDB soit pr√™t (environ 30 secondes)
kubectl wait --for=condition=ready pod -l app=mongo --timeout=120s

# D√©ployer l'API et le Worker
kubectl apply -f k8s-app.yaml

# V√©rifier que tout tourne
kubectl get pods
```

**Sortie attendue :**
```
NAME                              READY   STATUS    RESTARTS   AGE
api-deployment-xxx                1/1     Running   0          30s
mongo-deployment-xxx              1/1     Running   0          60s
worker-deployment-xxx             1/1     Running   0          30s
```

### 6. Installer Prometheus + Grafana

```bash
# Ajouter le repo Helm de Prometheus
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# Installer Prometheus + Grafana (monitoring complet)
helm install monitoring prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --create-namespace \
  --wait --timeout 5m

# V√©rifier que tout est install√©
kubectl get pods -n monitoring
```

**Sortie attendue :**
```
NAME                                                     READY   STATUS    RESTARTS   AGE
monitoring-grafana-xxx                                   3/3     Running   0          2m
monitoring-kube-prometheus-operator-xxx                  1/1     Running   0          2m
monitoring-kube-state-metrics-xxx                        1/1     Running   0          2m
monitoring-prometheus-node-exporter-xxx                  1/1     Running   0          2m
prometheus-monitoring-kube-prometheus-prometheus-0       2/2     Running   0          2m
```

### 7. Installer Airflow (Orchestration)

**‚ö†Ô∏è IMPORTANT : Airflow 2.10.3 avec Persistent Volume**

Airflow 3.0 a un bug avec les ConfigMaps Kubernetes (symlinks r√©cursifs). Nous utilisons donc Airflow 2.10.3 avec un Persistent Volume pointant vers le dossier local `dags/`.

```bash
# Ajouter le repo Helm d'Airflow
helm repo add apache-airflow https://airflow.apache.org
helm repo update

# Cr√©er le namespace Airflow
kubectl create namespace airflow

# Cr√©er le Persistent Volume pour les DAGs
kubectl apply -f k8s-airflow-dags-pv.yaml

# V√©rifier que le PV est cr√©√©
kubectl get pv airflow-dags-pv
kubectl get pvc airflow-dags-pvc -n airflow
```

**Sortie attendue :**
```
NAME              CAPACITY   ACCESS MODES   STATUS   CLAIM
airflow-dags-pv   1Gi        RWX            Bound    airflow/airflow-dags-pvc
```

**Installer Airflow avec le fichier de configuration :**

```bash
# Installer Airflow 2.10.3 avec PV pour les DAGs
helm install airflow apache-airflow/airflow \
  --namespace airflow \
  -f airflow-values.yaml \
  --timeout 10m \
  --wait

# Attendre que tous les pods soient pr√™ts (environ 3-5 minutes)
kubectl get pods -n airflow -w
```

**Sortie attendue (apr√®s 3-5 min) :**
```
NAME                                 READY   STATUS    RESTARTS   AGE
airflow-postgresql-0                 1/1     Running   0          3m
airflow-scheduler-xxx                3/3     Running   0          2m
airflow-triggerer-xxx                1/1     Running   0          2m
airflow-webserver-xxx                1/1     Running   0          2m
```

**Acc√©der √† l'interface Airflow :**

```bash
# Port-forward vers Airflow UI
kubectl port-forward -n airflow svc/airflow-webserver 8080:8080 &

# Ouvrir dans le navigateur : http://localhost:8080
# Username: admin
# Password: admin
```

**V√©rifier que le DAG est charg√© :**
1. Ouvre http://localhost:8080
2. Login avec `admin` / `admin`
3. Tu devrais voir le DAG `cgu_analysis_pipeline` avec 4 tasks :
   - ‚úÖ check_environment
   - ‚úÖ run_cgu_analysis
   - ‚úÖ sync_metrics
   - ‚úÖ final_report

---

## üß™ Tester le Pipeline Complet

### Test Complet du Workflow End-to-End

**Objectif** : Analyser les CGU Spotify avec Claude AI, stocker dans MongoDB, synchroniser les m√©triques Prometheus, visualiser dans Grafana et orchestrer avec Airflow.

### √âtape 1 : Port-forward MongoDB

```bash
# Ouvrir un port-forward vers MongoDB (laisser tourner dans un terminal)
kubectl port-forward -n default svc/mongo-service 27017:27017
```

### √âtape 2 : Analyser le fichier Spotify avec le Worker

**Ouvrir un NOUVEAU terminal** et ex√©cuter :

```bash
# Activer l'environnement Python
cd /chemin/vers/le/projet
source .venv/bin/activate

# Lancer l'analyse
cat raw_data/spotify_tc.txt | \
  MONGO_HOSTNAME=localhost MONGO_PORT=27017 \
  python worker.py \
  --task-id "spotify-demo-$(date +%s)" \
  --source-name "spotify" \
  --use-stdin
```

**Sortie attendue :**
```
[WORKER] Starting analysis task
[WORKER] Task ID: spotify-demo-1234567890
[WORKER] Source: spotify
[WORKER] Reading text content from stdin...
[WORKER] Text length: 54265 characters
[WORKER] Connecting to MongoDB at localhost:27017
[WORKER] MongoDB connection successful
[WORKER] Starting AI analysis...
[OK] spotify (Risk: 72/100)
[WORKER] Analysis completed successfully
[WORKER] Task finished and saved to MongoDB
```

### √âtape 3 : V√©rifier les donn√©es dans MongoDB

```bash
# Compter les analyses dans MongoDB
kubectl exec -n default deployment/mongo-deployment -- \
  mongosh too_long_to_read --quiet --eval "db.analytic_reports.countDocuments()"

# Voir la derni√®re analyse Spotify
kubectl exec -n default deployment/mongo-deployment -- \
  mongosh too_long_to_read --quiet --eval \
  "db.analytic_reports.findOne({source_name: 'spotify'}, {status: 1, 'report.risk_scores': 1})"
```

**Sortie attendue :**
```json
{
  "_id": ObjectId("..."),
  "status": "completed",
  "report": {
    "risk_scores": {
      "overall": 72,
      "data_privacy": 65,
      "termination_risk": 75,
      "legal_protection": 82,
      "transparency": 58
    }
  }
}
```

### √âtape 4 : Synchroniser les m√©triques Prometheus

```bash
# Port-forward vers l'API (nouveau terminal ou en background)
kubectl port-forward -n default svc/api-service 8000:8000 &

# Attendre 3 secondes
sleep 3

# Synchroniser les m√©triques depuis MongoDB vers Prometheus
curl http://localhost:8000/api/v1/sync-metrics
```

**Sortie attendue :**
```json
{
  "message": "Metrics synchronized successfully",
  "stats": {
    "spotify": 1
  },
  "total": 1
}
```

### √âtape 5 : V√©rifier les m√©triques Prometheus

```bash
# Voir toutes les m√©triques Spotify
curl -s http://localhost:8000/metrics | grep 'source_name="spotify"'
```

**Sortie attendue :**
```
cgu_analyses_count{source_name="spotify"} 1.0
cgu_last_risk_score{source_name="spotify"} 72.0
cgu_data_privacy_score{source_name="spotify"} 65.0
cgu_termination_risk_score{source_name="spotify"} 75.0
cgu_legal_protection_score{source_name="spotify"} 82.0
cgu_transparency_score{source_name="spotify"} 58.0
cgu_problematic_clauses{source_name="spotify"} 10.0
```

### √âtape 6 : Acc√©der √† Grafana et visualiser

```bash
# Port-forward vers Grafana
kubectl port-forward -n monitoring svc/grafana 3000:80 &

# Ou utilise le script :
./access_grafana.sh
```

**Ouvre ton navigateur :**
- URL : http://localhost:3000
- Username : `admin`
- Password : `admin`

**Dans Grafana :**
1. Va dans "Explore" (ic√¥ne boussole √† gauche)
2. S√©lectionne "Prometheus" comme source de donn√©es
3. Entre cette requ√™te :
   ```
   cgu_last_risk_score{source_name="Spotify"}
   ```
4. Clique sur "Run query"
5. Tu devrais voir le score **72** !

**Sortie attendue dans Grafana :**
```
cgu_last_risk_score{source_name="Spotify"} = 72
cgu_data_privacy_score{source_name="Spotify"} = 65
cgu_termination_risk_score{source_name="Spotify"} = 75
cgu_problematic_clauses{source_name="Spotify"} = 10
```

### √âtape 7 : Tester l'orchestration Airflow

**Port-forward vers Airflow UI :**

```bash
# Port-forward vers Airflow
kubectl port-forward -n airflow svc/airflow-webserver 8080:8080 &
```

**Ouvre ton navigateur :**
- URL : http://localhost:8080
- Username : `admin`
- Password : `admin`

**Tester le DAG :**

1. Clique sur le DAG `cgu_analysis_pipeline` dans la liste
2. Clique sur le bouton "Trigger DAG" (ic√¥ne play ‚ñ∂Ô∏è en haut √† droite)
3. Confirme en cliquant sur "Trigger"
4. Attends quelques secondes et rafra√Æchis la page

**Sortie attendue :**
- Les 4 tasks doivent √™tre en vert (SUCCESS) :
  - ‚úÖ check_environment
  - ‚úÖ run_cgu_analysis
  - ‚úÖ sync_metrics
  - ‚úÖ final_report

**Voir les logs d'une task :**
1. Clique sur une task (ex: `run_cgu_analysis`)
2. Clique sur "Log"
3. Tu verras les d√©tails de l'ex√©cution avec les scores affich√©s

**Logs attendus pour `run_cgu_analysis` :**
```
===========================================
ü§ñ ANALYSE DES CGU EN COURS
===========================================

üìÑ Source : Spotify Terms & Conditions
üìè Longueur : ~54,000 caract√®res

üîÑ Analyse avec Claude AI...

‚úÖ Analyse termin√©e !

üìä R√âSULTATS :
   ‚Ä¢ Score global : 72/100 (Pr√©occupant)
   ‚Ä¢ Data Privacy : 65/100
   ‚Ä¢ Termination Risk : 75/100
   ‚Ä¢ Legal Protection : 82/100
   ‚Ä¢ Transparency : 58/100
   ‚Ä¢ Clauses dangereuses : 10

üíæ Donn√©es sauvegard√©es dans MongoDB
```

---

## üéØ Script de Test Rapide

Tu peux utiliser ce script bash pour tout tester d'un coup :

```bash
#!/bin/bash
# test_complete.sh

echo "üöÄ Test complet du pipeline 2Long2Read"
echo "========================================"

# 1. Port-forward MongoDB
echo "1Ô∏è‚É£  D√©marrage port-forward MongoDB..."
pkill -f "kubectl port-forward.*mongo" 2>/dev/null
kubectl port-forward -n default svc/mongo-service 27017:27017 > /dev/null 2>&1 &
sleep 3

# 2. Analyse Spotify
echo "2Ô∏è‚É£  Analyse des CGU Spotify..."
TASK_ID="test-$(date +%s)"
cat raw_data/spotify_tc.txt | \
  MONGO_HOSTNAME=localhost MONGO_PORT=27017 \
  .venv/bin/python worker.py \
  --task-id "$TASK_ID" \
  --source-name "spotify" \
  --use-stdin | grep "\[OK\]"

# 3. V√©rification MongoDB
echo "3Ô∏è‚É£  V√©rification MongoDB..."
COUNT=$(kubectl exec -n default deployment/mongo-deployment -- \
  mongosh too_long_to_read --quiet --eval \
  "db.analytic_reports.countDocuments({source_name: 'spotify'})")
echo "   ‚úÖ Analyses Spotify dans MongoDB: $COUNT"

# 4. Port-forward API
echo "4Ô∏è‚É£  D√©marrage port-forward API..."
pkill -f "kubectl port-forward.*api" 2>/dev/null
kubectl port-forward -n default svc/api-service 8000:8000 > /dev/null 2>&1 &
sleep 3

# 5. Sync m√©triques
echo "5Ô∏è‚É£  Synchronisation des m√©triques..."
curl -s http://localhost:8000/api/v1/sync-metrics | grep -o '"total":[0-9]*'

# 6. V√©rification m√©triques
echo "6Ô∏è‚É£  V√©rification des m√©triques Prometheus..."
curl -s http://localhost:8000/metrics | grep 'cgu_last_risk_score{source_name="spotify"}'

echo ""
echo "‚úÖ Test termin√© ! Acc√®de √† Grafana avec: ./access_grafana.sh"
echo "   URL: http://localhost:3000 (admin / prom-operator)"
```

Rends-le ex√©cutable et lance-le :

```bash
chmod +x test_complete.sh
./test_complete.sh
```

---

## üìä R√©sultats d'Analyse Spotify

L'analyse compl√®te de Spotify r√©v√®le :

### Scores de Risque
- **Score Global** : 72/100 (Pr√©occupant)
- **Confidentialit√© des donn√©es** : 65/100
- **Risque de r√©siliation** : 75/100
- **Protection l√©gale** : 82/100
- **Transparence** : 58/100

### Clauses Probl√©matiques Identifi√©es (10 au total)
1. ‚ö†Ô∏è **Arbitrage obligatoire** (CRITIQUE) - Pas de recours collectifs
2. ‚ö†Ô∏è **Licence mondiale irr√©vocable** sur votre contenu
3. ‚ö†Ô∏è **R√©siliation sans remboursement**
4. ‚ö†Ô∏è **Limitation de responsabilit√©** √† 30$
5. Et 6 autres clauses √† risque...

---

## üèóÔ∏è Architecture du Projet

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Fichier Spotify‚îÇ
‚îÇ  (raw_data/)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Worker Python  ‚îÇ
‚îÇ  (Claude AI)    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ Cl√© API Anthropic
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    MongoDB      ‚îÇ
‚îÇ  (stockage)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   API FastAPI   ‚îÇ
‚îÇ  /metrics       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Prometheus    ‚îÇ
‚îÇ  (scraping)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Grafana      ‚îÇ
‚îÇ (visualisation) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîß Commandes Utiles

### V√©rifier l'√©tat des pods

```bash
# Tous les pods
kubectl get pods --all-namespaces

# Pods de l'application
kubectl get pods -n default

# Pods de monitoring
kubectl get pods -n monitoring
```

### Red√©marrer un composant

```bash
# Red√©marrer l'API (apr√®s modification du code)
kubectl rollout restart deployment/api-deployment

# Red√©marrer le Worker
kubectl rollout restart deployment/worker-deployment

# Attendre que le d√©ploiement soit pr√™t
kubectl rollout status deployment/api-deployment
```

### Voir les logs

```bash
# Logs de l'API
kubectl logs -f deployment/api-deployment

# Logs du Worker
kubectl logs -f deployment/worker-deployment

# Logs de MongoDB
kubectl logs -f deployment/mongo-deployment
```

### Nettoyer MongoDB (repartir de z√©ro)

```bash
kubectl exec -n default deployment/mongo-deployment -- \
  mongosh too_long_to_read --eval "db.analytic_reports.deleteMany({})"
```

---

## üêõ D√©pannage

### Probl√®me : MongoDB inaccessible

```bash
# V√©rifier que MongoDB tourne
kubectl get pods -l app=mongo

# V√©rifier les logs
kubectl logs deployment/mongo-deployment

# Red√©marrer MongoDB
kubectl rollout restart deployment/mongo-deployment
```

### Probl√®me : M√©triques √† 0 dans Grafana

```bash
# 1. V√©rifier que l'analyse est dans MongoDB
kubectl exec -n default deployment/mongo-deployment -- \
  mongosh too_long_to_read --quiet --eval \
  "db.analytic_reports.countDocuments({source_name: 'spotify'})"

# 2. Re-synchroniser les m√©triques
curl http://localhost:8000/api/v1/sync-metrics

# 3. V√©rifier les m√©triques dans Prometheus
curl http://localhost:8000/metrics | grep spotify
```

### Probl√®me : Image Docker pas trouv√©e

```bash
# V√©rifier que les images existent
docker images | grep 2long2read

# Si elles n'existent pas, les reconstruire
docker build -t 2long2read-api:latest -f Dockerfile .
docker build -t 2long2read-worker:latest -f Dockerfile.worker .

# Red√©marrer les pods pour utiliser les nouvelles images
kubectl rollout restart deployment/api-deployment
kubectl rollout restart deployment/worker-deployment
```

---

## üéì Pour la D√©mo

### 1. Pr√©paration (5 min avant)

```bash
# S'assurer que tout tourne
kubectl get pods --all-namespaces

# Port-forwards en place
kubectl port-forward -n default svc/mongo-service 27017:27017 &
kubectl port-forward -n default svc/api-service 8000:8000 &
kubectl port-forward -n monitoring svc/monitoring-grafana 3000:80 &

# Nettoyer MongoDB pour partir de z√©ro (optionnel)
kubectl exec -n default deployment/mongo-deployment -- \
  mongosh too_long_to_read --eval "db.analytic_reports.deleteMany({})"
```

### 2. D√©monstration Live (10 min)

**√âtape 1 : Montrer le fichier d'entr√©e**
```bash
# Montrer les premi√®res lignes du fichier Spotify
head -20 raw_data/spotify_tc.txt
wc -w raw_data/spotify_tc.txt  # Nombre de mots
```

**√âtape 2 : Lancer l'analyse en direct**
```bash
cat raw_data/spotify_tc.txt | \
  MONGO_HOSTNAME=localhost MONGO_PORT=27017 \
  .venv/bin/python worker.py \
  --task-id "demo-live-$(date +%s)" \
  --source-name "spotify" \
  --use-stdin
```

**√âtape 3 : Montrer les donn√©es dans MongoDB**
```bash
kubectl exec -n default deployment/mongo-deployment -- \
  mongosh too_long_to_read --quiet --eval \
  "db.analytic_reports.find({source_name: 'spotify'}).sort({_id: -1}).limit(1).pretty()"
```

**√âtape 4 : Synchroniser et montrer les m√©triques**
```bash
# Sync
curl http://localhost:8000/api/v1/sync-metrics

# Voir les m√©triques
curl http://localhost:8000/metrics | grep spotify
```

**√âtape 5 : Ouvrir Grafana**
- Navigateur : http://localhost:3000
- Login : admin / prom-operator
- Aller dans "Explore"
- Requ√™te : `cgu_last_risk_score{source_name="spotify"}`
- Montrer le graphique avec le score de 72

### 3. Points √† Souligner

‚úÖ **Technologies utilis√©es** :
- Docker (conteneurisation)
- Kubernetes (orchestration)
- MongoDB (base de donn√©es)
- Claude AI (analyse IA)
- Prometheus (m√©triques)
- Grafana (visualisation)

‚úÖ **Pipeline complet fonctionnel** :
- Fichier texte ‚Üí Analyse IA ‚Üí Stockage ‚Üí M√©triques ‚Üí Visualisation

‚úÖ **Scores de risque pr√©cis** :
- Analyse s√©mantique approfondie des CGU
- Identification des clauses dangereuses
- Recommandations pour les utilisateurs

---

## üìÅ Structure du Projet

```
.
‚îú‚îÄ‚îÄ README.md                  # Ce fichier
‚îú‚îÄ‚îÄ requirements.txt           # D√©pendances Python
‚îú‚îÄ‚îÄ Dockerfile                 # Image Docker de l'API
‚îú‚îÄ‚îÄ Dockerfile.worker          # Image Docker du Worker
‚îú‚îÄ‚îÄ main.py                    # API FastAPI avec m√©triques Prometheus
‚îú‚îÄ‚îÄ worker.py                  # Worker d'analyse (Claude AI)
‚îú‚îÄ‚îÄ ai_analyzer.py             # Logique d'analyse IA
‚îú‚îÄ‚îÄ k8s-app.yaml              # D√©ploiement API + Worker
‚îú‚îÄ‚îÄ k8s-infra.yaml            # D√©ploiement MongoDB
‚îú‚îÄ‚îÄ access_grafana.sh          # Script d'acc√®s Grafana
‚îú‚îÄ‚îÄ raw_data/
‚îÇ   ‚îî‚îÄ‚îÄ spotify_tc.txt         # Fichier de test Spotify
‚îî‚îÄ‚îÄ config/
    ‚îî‚îÄ‚îÄ grafana_spotify_dashboard.json  # Dashboard Grafana
```

---

## üöÄ Prochaines √âtapes

Une fois que tout fonctionne chez toi, tu peux :

1. **Analyser d'autres fichiers** : Ajoute tes propres fichiers T&C dans `raw_data/`
2. **Cr√©er des dashboards Grafana** : Importe `config/grafana_spotify_dashboard.json`
3. **Int√©grer Airflow** : Pour l'orchestration automatique (√† venir)
4. **Ajouter d'autres sources** : Google, Facebook, Amazon, etc.

---

## üìû Support

Si tu rencontres des probl√®mes :

1. V√©rifie que Docker Desktop est d√©marr√©
2. V√©rifie que tous les pods sont en √©tat `Running`
3. V√©rifie les logs des pods concern√©s
4. Consulte la section "D√©pannage" ci-dessus

---

## ‚ú® R√©sum√© des Commandes Essentielles

```bash
# Setup initial
kubectl create secret generic claude-api-key-secret --from-literal=ANTHROPIC_API_KEY="ta-cl√©"
docker build -t 2long2read-api:latest -f Dockerfile .
docker build -t 2long2read-worker:latest -f Dockerfile.worker .
kubectl apply -f k8s-infra.yaml
kubectl apply -f k8s-app.yaml
helm install monitoring prometheus-community/kube-prometheus-stack -n monitoring --create-namespace

# Test complet
kubectl port-forward -n default svc/mongo-service 27017:27017 &
cat raw_data/spotify_tc.txt | MONGO_HOSTNAME=localhost MONGO_PORT=27017 .venv/bin/python worker.py --task-id "test-$(date +%s)" --source-name "spotify" --use-stdin
kubectl port-forward -n default svc/api-service 8000:8000 &
curl http://localhost:8000/api/v1/sync-metrics
./access_grafana.sh
```

---

**Bon courage pour ta d√©mo ! üéâ**
