# ğŸš€ 2Long2Read - Analyseur de CGU avec Claude AI

**SystÃ¨me d'analyse automatique de Terms & Conditions utilisant Claude AI, MongoDB, Prometheus et Grafana sur Kubernetes.**

---

## ğŸ“‹ PrÃ©requis

Avant de commencer, assure-toi d'avoir :

- **Docker Desktop** installÃ© et en cours d'exÃ©cution
- **kubectl** installÃ© (inclus avec Docker Desktop)
- **Helm** installÃ© (gestionnaire de packages Kubernetes)
- **Python 3.11+** avec pip
- **Une clÃ© API Anthropic** (Claude AI)

### VÃ©rification rapide

```bash
docker --version
kubectl version --client
helm version
python3 --version
```

---

## ğŸ› ï¸ Installation ComplÃ¨te (Ã‰tape par Ã‰tape)

### 1. Cloner le projet

```bash
git clone <url-du-repo>
cd theprojectthathelpsyoubetterunderstndhowyourdataisusedineverycompanystermsandconditionsbecausenooneverreadsthem
```

### 2. Configurer l'environnement Python

```bash
# CrÃ©er un environnement virtuel
python3 -m venv .venv

# Activer l'environnement
source .venv/bin/activate  # macOS/Linux
# ou
.venv\Scripts\activate     # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### 3. Configurer la clÃ© API Claude

```bash
# CrÃ©er le secret Kubernetes pour Claude AI
kubectl create secret generic claude-api-key-secret \
  --from-literal=ANTHROPIC_API_KEY="ta-clÃ©-api-ici"

# VÃ©rifier que le secret est crÃ©Ã©
kubectl get secrets
```

### 4. Construire les images Docker

```bash
# Image de l'API
docker build -t 2long2read-api:latest -f Dockerfile .

# Image du Worker
docker build -t 2long2read-worker:latest -f Dockerfile.worker .

# VÃ©rifier les images
docker images | grep 2long2read
```

### 5. DÃ©ployer l'infrastructure sur Kubernetes

```bash
# DÃ©ployer MongoDB
kubectl apply -f k8s-infra.yaml

# Attendre que MongoDB soit prÃªt (environ 30 secondes)
kubectl wait --for=condition=ready pod -l app=mongo --timeout=120s

# DÃ©ployer l'API et le Worker
kubectl apply -f k8s-app.yaml

# VÃ©rifier que tout tourne
kubectl get pods
```

**Sortie attendue :**
```
NAME                              READY   STATUS    RESTARTS   AGE
api-deployment-xxx                1/1     Running   0          30s
mongo-deployment-xxx              1/1     Running   0          60s
worker-deployment-xxx             1/1     Running   0          30s
```

### 6. Installer Prometheus + Grafana

```bash
# Ajouter le repo Helm de Prometheus
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# Installer Prometheus + Grafana (monitoring complet)
helm install monitoring prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --create-namespace \
  --wait --timeout 5m

# VÃ©rifier que tout est installÃ©
kubectl get pods -n monitoring
```

**Sortie attendue :**
```
NAME                                                     READY   STATUS    RESTARTS   AGE
monitoring-grafana-xxx                                   3/3     Running   0          2m
monitoring-kube-prometheus-operator-xxx                  1/1     Running   0          2m
monitoring-kube-state-metrics-xxx                        1/1     Running   0          2m
monitoring-prometheus-node-exporter-xxx                  1/1     Running   0          2m
prometheus-monitoring-kube-prometheus-prometheus-0       2/2     Running   0          2m
```

### 7. Installer Airflow (Orchestration)

**âš ï¸ IMPORTANT : Airflow 2.10.3 avec Persistent Volume**

Airflow 3.0 a un bug avec les ConfigMaps Kubernetes (symlinks rÃ©cursifs). Nous utilisons donc Airflow 2.10.3 avec un Persistent Volume pointant vers le dossier local `dags/`.

```bash
# Ajouter le repo Helm d'Airflow
helm repo add apache-airflow https://airflow.apache.org
helm repo update

# CrÃ©er le namespace Airflow
kubectl create namespace airflow

# CrÃ©er le Persistent Volume pour les DAGs
kubectl apply -f k8s-airflow-dags-pv.yaml

# VÃ©rifier que le PV est crÃ©Ã©
kubectl get pv airflow-dags-pv
kubectl get pvc airflow-dags-pvc -n airflow
```

**Sortie attendue :**
```
NAME              CAPACITY   ACCESS MODES   STATUS   CLAIM
airflow-dags-pv   1Gi        RWX            Bound    airflow/airflow-dags-pvc
```

**Installer Airflow avec le fichier de configuration :**

```bash
# Installer Airflow 2.10.3 avec PV pour les DAGs
helm install airflow apache-airflow/airflow \
  --namespace airflow \
  -f airflow-values.yaml \
  --timeout 10m \
  --wait

# Attendre que tous les pods soient prÃªts (environ 3-5 minutes)
kubectl get pods -n airflow -w
```

**Sortie attendue (aprÃ¨s 3-5 min) :**
```
NAME                                 READY   STATUS    RESTARTS   AGE
airflow-postgresql-0                 1/1     Running   0          3m
airflow-scheduler-xxx                3/3     Running   0          2m
airflow-triggerer-xxx                1/1     Running   0          2m
airflow-webserver-xxx                1/1     Running   0          2m
```

**AccÃ©der Ã  l'interface Airflow :**

```bash
# Port-forward vers Airflow UI
kubectl port-forward -n airflow svc/airflow-webserver 8080:8080 &

# Ouvrir dans le navigateur : http://localhost:8080
# Username: admin
# Password: admin
```

**VÃ©rifier que le DAG est chargÃ© :**
1. Ouvre http://localhost:8080
2. Login avec `admin` / `admin`
3. Tu devrais voir le DAG `cgu_analysis_pipeline` avec 4 tasks :
   - âœ… check_environment
   - âœ… run_cgu_analysis
   - âœ… sync_metrics
   - âœ… final_report

---

## ğŸ§ª Tester le Pipeline Complet

### Test Complet du Workflow End-to-End

**Objectif** : Analyser les CGU Spotify avec Claude AI, stocker dans MongoDB, synchroniser les mÃ©triques Prometheus, visualiser dans Grafana et orchestrer avec Airflow.

### Ã‰tape 1 : Port-forward MongoDB

```bash
# Ouvrir un port-forward vers MongoDB (laisser tourner dans un terminal)
kubectl port-forward -n default svc/mongo-service 27017:27017
```

### Ã‰tape 2 : Analyser le fichier Spotify avec le Worker

**Ouvrir un NOUVEAU terminal** et exÃ©cuter :

```bash
# Activer l'environnement Python
cd /chemin/vers/le/projet
source .venv/bin/activate

# Lancer l'analyse
cat raw_data/spotify_tc.txt | \
  MONGO_HOSTNAME=localhost MONGO_PORT=27017 \
  python worker.py \
  --task-id "spotify-demo-$(date +%s)" \
  --source-name "spotify" \
  --use-stdin
```

**Sortie attendue :**
```
[WORKER] Starting analysis task
[WORKER] Task ID: spotify-demo-1234567890
[WORKER] Source: spotify
[WORKER] Reading text content from stdin...
[WORKER] Text length: 54265 characters
[WORKER] Connecting to MongoDB at localhost:27017
[WORKER] MongoDB connection successful
[WORKER] Starting AI analysis...
[OK] spotify (Risk: 72/100)
[WORKER] Analysis completed successfully
[WORKER] Task finished and saved to MongoDB
```

### Ã‰tape 3 : VÃ©rifier les donnÃ©es dans MongoDB

```bash
# Compter les analyses dans MongoDB
kubectl exec -n default deployment/mongo-deployment -- \
  mongosh too_long_to_read --quiet --eval "db.analytic_reports.countDocuments()"

# Voir la derniÃ¨re analyse Spotify
kubectl exec -n default deployment/mongo-deployment -- \
  mongosh too_long_to_read --quiet --eval \
  "db.analytic_reports.findOne({source_name: 'spotify'}, {status: 1, 'report.risk_scores': 1})"
```

**Sortie attendue :**
```json
{
  "_id": ObjectId("..."),
  "status": "completed",
  "report": {
    "risk_scores": {
      "overall": 72,
      "data_privacy": 65,
      "termination_risk": 75,
      "legal_protection": 82,
      "transparency": 58
    }
  }
}
```

### Ã‰tape 4 : Synchroniser les mÃ©triques Prometheus

```bash
# Port-forward vers l'API (nouveau terminal ou en background)
kubectl port-forward -n default svc/api-service 8000:8000 &

# Attendre 3 secondes
sleep 3

# Synchroniser les mÃ©triques depuis MongoDB vers Prometheus
curl http://localhost:8000/api/v1/sync-metrics
```

**Sortie attendue :**
```json
{
  "message": "Metrics synchronized successfully",
  "stats": {
    "spotify": 1
  },
  "total": 1
}
```

### Ã‰tape 5 : VÃ©rifier les mÃ©triques Prometheus

```bash
# Voir toutes les mÃ©triques Spotify
curl -s http://localhost:8000/metrics | grep 'source_name="spotify"'
```

**Sortie attendue :**
```
cgu_analyses_count{source_name="spotify"} 1.0
cgu_last_risk_score{source_name="spotify"} 72.0
cgu_data_privacy_score{source_name="spotify"} 65.0
cgu_termination_risk_score{source_name="spotify"} 75.0
cgu_legal_protection_score{source_name="spotify"} 82.0
cgu_transparency_score{source_name="spotify"} 58.0
cgu_problematic_clauses{source_name="spotify"} 10.0
```

### Ã‰tape 6 : AccÃ©der Ã  Grafana et visualiser

```bash
# Port-forward vers Grafana
kubectl port-forward -n monitoring svc/grafana 3000:80 &

# Ou utilise le script :
./access_grafana.sh
```

**Ouvre ton navigateur :**
- URL : http://localhost:3000
- Username : `admin`
- Password : `admin`

**Dans Grafana :**
1. Va dans "Explore" (icÃ´ne boussole Ã  gauche)
2. SÃ©lectionne "Prometheus" comme source de donnÃ©es
3. Entre cette requÃªte :
   ```
   cgu_last_risk_score{source_name="Spotify"}
   ```
4. Clique sur "Run query"
5. Tu devrais voir le score **72** !

**Sortie attendue dans Grafana :**
```
cgu_last_risk_score{source_name="Spotify"} = 72
cgu_data_privacy_score{source_name="Spotify"} = 65
cgu_termination_risk_score{source_name="Spotify"} = 75
cgu_problematic_clauses{source_name="Spotify"} = 10
```

### Ã‰tape 7 : Tester l'orchestration Airflow

**Port-forward vers Airflow UI :**

```bash
# Port-forward vers Airflow
kubectl port-forward -n airflow svc/airflow-webserver 8080:8080 &
```

**Ouvre ton navigateur :**
- URL : http://localhost:8080
- Username : `admin`
- Password : `admin`

**Tester le DAG :**

1. Clique sur le DAG `cgu_analysis_pipeline` dans la liste
2. Clique sur le bouton "Trigger DAG" (icÃ´ne play â–¶ï¸ en haut Ã  droite)
3. Confirme en cliquant sur "Trigger"
4. Attends quelques secondes et rafraÃ®chis la page

**Sortie attendue :**
- Les 4 tasks doivent Ãªtre en vert (SUCCESS) :
  - âœ… check_environment
  - âœ… run_cgu_analysis
  - âœ… sync_metrics
  - âœ… final_report

**Voir les logs d'une task :**
1. Clique sur une task (ex: `run_cgu_analysis`)
2. Clique sur "Log"
3. Tu verras les dÃ©tails de l'exÃ©cution avec les scores affichÃ©s

**Logs attendus pour `run_cgu_analysis` :**
```
===========================================
ğŸ¤– ANALYSE DES CGU EN COURS
===========================================

ğŸ“„ Source : Spotify Terms & Conditions
ğŸ“ Longueur : ~54,000 caractÃ¨res

ğŸ”„ Analyse avec Claude AI...

âœ… Analyse terminÃ©e !

ğŸ“Š RÃ‰SULTATS :
   â€¢ Score global : 72/100 (PrÃ©occupant)
   â€¢ Data Privacy : 65/100
   â€¢ Termination Risk : 75/100
   â€¢ Legal Protection : 82/100
   â€¢ Transparency : 58/100
   â€¢ Clauses dangereuses : 10

ğŸ’¾ DonnÃ©es sauvegardÃ©es dans MongoDB
```

---

## ğŸ¯ Script de Test Rapide

Tu peux utiliser ce script bash pour tout tester d'un coup :

```bash
#!/bin/bash
# test_complete.sh

echo "ğŸš€ Test complet du pipeline 2Long2Read"
echo "========================================"

# 1. Port-forward MongoDB
echo "1ï¸âƒ£  DÃ©marrage port-forward MongoDB..."
pkill -f "kubectl port-forward.*mongo" 2>/dev/null
kubectl port-forward -n default svc/mongo-service 27017:27017 > /dev/null 2>&1 &
sleep 3

# 2. Analyse Spotify
echo "2ï¸âƒ£  Analyse des CGU Spotify..."
TASK_ID="test-$(date +%s)"
cat raw_data/spotify_tc.txt | \
  MONGO_HOSTNAME=localhost MONGO_PORT=27017 \
  .venv/bin/python worker.py \
  --task-id "$TASK_ID" \
  --source-name "spotify" \
  --use-stdin | grep "\[OK\]"

# 3. VÃ©rification MongoDB
echo "3ï¸âƒ£  VÃ©rification MongoDB..."
COUNT=$(kubectl exec -n default deployment/mongo-deployment -- \
  mongosh too_long_to_read --quiet --eval \
  "db.analytic_reports.countDocuments({source_name: 'spotify'})")
echo "   âœ… Analyses Spotify dans MongoDB: $COUNT"

# 4. Port-forward API
echo "4ï¸âƒ£  DÃ©marrage port-forward API..."
pkill -f "kubectl port-forward.*api" 2>/dev/null
kubectl port-forward -n default svc/api-service 8000:8000 > /dev/null 2>&1 &
sleep 3

# 5. Sync mÃ©triques
echo "5ï¸âƒ£  Synchronisation des mÃ©triques..."
curl -s http://localhost:8000/api/v1/sync-metrics | grep -o '"total":[0-9]*'

# 6. VÃ©rification mÃ©triques
echo "6ï¸âƒ£  VÃ©rification des mÃ©triques Prometheus..."
curl -s http://localhost:8000/metrics | grep 'cgu_last_risk_score{source_name="spotify"}'

echo ""
echo "âœ… Test terminÃ© ! AccÃ¨de Ã  Grafana avec: ./access_grafana.sh"
echo "   URL: http://localhost:3000 (admin / prom-operator)"
```

Rends-le exÃ©cutable et lance-le :

```bash
chmod +x test_complete.sh
./test_complete.sh
```

---

## ğŸ“Š RÃ©sultats d'Analyse Spotify

L'analyse complÃ¨te de Spotify rÃ©vÃ¨le :

### Scores de Risque
- **Score Global** : 72/100 (PrÃ©occupant)
- **ConfidentialitÃ© des donnÃ©es** : 65/100
- **Risque de rÃ©siliation** : 75/100
- **Protection lÃ©gale** : 82/100
- **Transparence** : 58/100

### Clauses ProblÃ©matiques IdentifiÃ©es (10 au total)
1. âš ï¸ **Arbitrage obligatoire** (CRITIQUE) - Pas de recours collectifs
2. âš ï¸ **Licence mondiale irrÃ©vocable** sur votre contenu
3. âš ï¸ **RÃ©siliation sans remboursement**
4. âš ï¸ **Limitation de responsabilitÃ©** Ã  30$
5. Et 6 autres clauses Ã  risque...

---

## ğŸ—ï¸ Architecture du Projet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Fichier Spotifyâ”‚
â”‚  (raw_data/)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Worker Python  â”‚
â”‚  (Claude AI)    â”‚â—„â”€â”€â”€ ClÃ© API Anthropic
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    MongoDB      â”‚
â”‚  (stockage)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API FastAPI   â”‚
â”‚  /metrics       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Prometheus    â”‚
â”‚  (scraping)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Grafana      â”‚
â”‚ (visualisation) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Commandes Utiles

### VÃ©rifier l'Ã©tat des pods

```bash
# Tous les pods
kubectl get pods --all-namespaces

# Pods de l'application
kubectl get pods -n default

# Pods de monitoring
kubectl get pods -n monitoring
```

### RedÃ©marrer un composant

```bash
# RedÃ©marrer l'API (aprÃ¨s modification du code)
kubectl rollout restart deployment/api-deployment

# RedÃ©marrer le Worker
kubectl rollout restart deployment/worker-deployment

# Attendre que le dÃ©ploiement soit prÃªt
kubectl rollout status deployment/api-deployment
```

### Voir les logs

```bash
# Logs de l'API
kubectl logs -f deployment/api-deployment

# Logs du Worker
kubectl logs -f deployment/worker-deployment

# Logs de MongoDB
kubectl logs -f deployment/mongo-deployment
```

### Nettoyer MongoDB (repartir de zÃ©ro)

```bash
kubectl exec -n default deployment/mongo-deployment -- \
  mongosh too_long_to_read --eval "db.analytic_reports.deleteMany({})"
```

---

## ğŸ› DÃ©pannage

### ProblÃ¨me : MongoDB inaccessible

```bash
# VÃ©rifier que MongoDB tourne
kubectl get pods -l app=mongo

# VÃ©rifier les logs
kubectl logs deployment/mongo-deployment

# RedÃ©marrer MongoDB
kubectl rollout restart deployment/mongo-deployment
```

### ProblÃ¨me : MÃ©triques Ã  0 dans Grafana

```bash
# 1. VÃ©rifier que l'analyse est dans MongoDB
kubectl exec -n default deployment/mongo-deployment -- \
  mongosh too_long_to_read --quiet --eval \
  "db.analytic_reports.countDocuments({source_name: 'spotify'})"

# 2. Re-synchroniser les mÃ©triques
curl http://localhost:8000/api/v1/sync-metrics

# 3. VÃ©rifier les mÃ©triques dans Prometheus
curl http://localhost:8000/metrics | grep spotify
```

### ProblÃ¨me : Image Docker pas trouvÃ©e

```bash
# VÃ©rifier que les images existent
docker images | grep 2long2read

# Si elles n'existent pas, les reconstruire
docker build -t 2long2read-api:latest -f Dockerfile .
docker build -t 2long2read-worker:latest -f Dockerfile.worker .

# RedÃ©marrer les pods pour utiliser les nouvelles images
kubectl rollout restart deployment/api-deployment
kubectl rollout restart deployment/worker-deployment
```

---

## ğŸ“ Pour la DÃ©mo

### 1. PrÃ©paration (5 min avant)

```bash
# S'assurer que tout tourne
kubectl get pods --all-namespaces

# Port-forwards en place
kubectl port-forward -n default svc/mongo-service 27017:27017 &
kubectl port-forward -n default svc/api-service 8000:8000 &
kubectl port-forward -n monitoring svc/monitoring-grafana 3000:80 &

# Nettoyer MongoDB pour partir de zÃ©ro (optionnel)
kubectl exec -n default deployment/mongo-deployment -- \
  mongosh too_long_to_read --eval "db.analytic_reports.deleteMany({})"
```

### 2. DÃ©monstration Live (10 min)

**Ã‰tape 1 : Montrer le fichier d'entrÃ©e**
```bash
# Montrer les premiÃ¨res lignes du fichier Spotify
head -20 raw_data/spotify_tc.txt
wc -w raw_data/spotify_tc.txt  # Nombre de mots
```

**Ã‰tape 2 : Lancer l'analyse en direct**
```bash
cat raw_data/spotify_tc.txt | \
  MONGO_HOSTNAME=localhost MONGO_PORT=27017 \
  .venv/bin/python worker.py \
  --task-id "demo-live-$(date +%s)" \
  --source-name "spotify" \
  --use-stdin
```

**Ã‰tape 3 : Montrer les donnÃ©es dans MongoDB**
```bash
kubectl exec -n default deployment/mongo-deployment -- \
  mongosh too_long_to_read --quiet --eval \
  "db.analytic_reports.find({source_name: 'spotify'}).sort({_id: -1}).limit(1).pretty()"
```

**Ã‰tape 4 : Synchroniser et montrer les mÃ©triques**
```bash
# Sync
curl http://localhost:8000/api/v1/sync-metrics

# Voir les mÃ©triques
curl http://localhost:8000/metrics | grep spotify
```

**Ã‰tape 5 : Ouvrir Grafana**
- Navigateur : http://localhost:3000
- Login : admin / prom-operator
- Aller dans "Explore"
- RequÃªte : `cgu_last_risk_score{source_name="spotify"}`
- Montrer le graphique avec le score de 72

### 3. Points Ã  Souligner

âœ… **Technologies utilisÃ©es** :
- Docker (conteneurisation)
- Kubernetes (orchestration)
- MongoDB (base de donnÃ©es)
- Claude AI (analyse IA)
- Prometheus (mÃ©triques)
- Grafana (visualisation)

âœ… **Pipeline complet fonctionnel** :
- Fichier texte â†’ Analyse IA â†’ Stockage â†’ MÃ©triques â†’ Visualisation

âœ… **Scores de risque prÃ©cis** :
- Analyse sÃ©mantique approfondie des CGU
- Identification des clauses dangereuses
- Recommandations pour les utilisateurs

---

## ğŸ“ Structure du Projet

```
.
â”œâ”€â”€ README.md                  # Ce fichier
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ Dockerfile                 # Image Docker de l'API
â”œâ”€â”€ Dockerfile.worker          # Image Docker du Worker
â”œâ”€â”€ main.py                    # API FastAPI avec mÃ©triques Prometheus
â”œâ”€â”€ worker.py                  # Worker d'analyse (Claude AI)
â”œâ”€â”€ ai_analyzer.py             # Logique d'analyse IA
â”œâ”€â”€ k8s-app.yaml              # DÃ©ploiement API + Worker
â”œâ”€â”€ k8s-infra.yaml            # DÃ©ploiement MongoDB
â”œâ”€â”€ access_grafana.sh          # Script d'accÃ¨s Grafana
â”œâ”€â”€ raw_data/
â”‚   â””â”€â”€ spotify_tc.txt         # Fichier de test Spotify
â””â”€â”€ config/
    â””â”€â”€ grafana_spotify_dashboard.json  # Dashboard Grafana
```

---

## ğŸš€ Prochaines Ã‰tapes

Une fois que tout fonctionne chez toi, tu peux :

1. **Analyser d'autres fichiers** : Ajoute tes propres fichiers T&C dans `raw_data/`
2. **CrÃ©er des dashboards Grafana** : Importe `config/grafana_spotify_dashboard.json`
3. **IntÃ©grer Airflow** : Pour l'orchestration automatique (Ã  venir)
4. **Ajouter d'autres sources** : Google, Facebook, Amazon, etc.

---

## ğŸ“ Support

Si tu rencontres des problÃ¨mes :

1. VÃ©rifie que Docker Desktop est dÃ©marrÃ©
2. VÃ©rifie que tous les pods sont en Ã©tat `Running`
3. VÃ©rifie les logs des pods concernÃ©s
4. Consulte la section "DÃ©pannage" ci-dessus

---

## âœ¨ RÃ©sumÃ© des Commandes Essentielles

```bash
# Setup initial
kubectl create secret generic claude-api-key-secret --from-literal=ANTHROPIC_API_KEY="ta-clÃ©"
docker build -t 2long2read-api:latest -f Dockerfile .
docker build -t 2long2read-worker:latest -f Dockerfile.worker .
kubectl apply -f k8s-infra.yaml
kubectl apply -f k8s-app.yaml
helm install monitoring prometheus-community/kube-prometheus-stack -n monitoring --create-namespace

# Test complet
kubectl port-forward -n default svc/mongo-service 27017:27017 &
cat raw_data/spotify_tc.txt | MONGO_HOSTNAME=localhost MONGO_PORT=27017 .venv/bin/python worker.py --task-id "test-$(date +%s)" --source-name "spotify" --use-stdin
kubectl port-forward -n default svc/api-service 8000:8000 &
curl http://localhost:8000/api/v1/sync-metrics
./access_grafana.sh
```

---

**Bon courage pour ta dÃ©mo ! ğŸ‰**
